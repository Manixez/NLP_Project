#!/bin/bash
# ==============================================================================
# ğŸš€ QUICK REFERENCE - Image Captioning Commands
# ==============================================================================

cat << 'EOF'

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    IMAGE CAPTIONING - QUICK COMMANDS                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¦ SETUP (Run Once)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Activate virtual environment:
   $ source NLP/bin/activate

2. Install dependencies:
   $ pip install -r requirements.txt

3. Download NLTK data:
   $ python -c "import nltk; nltk.download('punkt')"

4. Download FastText model (6.8 GB):
   $ mkdir -p fasttext && cd fasttext
   $ wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz
   $ gunzip cc.id.300.bin.gz
   $ cd ..

5. OR run automated setup:
   $ ./setup.sh


ğŸ“š PREPROCESSING (FASE 0)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Build vocabulary & embedding matrix (run ONCE before training):
$ python prepare_data.py

Output:
  âœ“ output/vocab/vocab.pkl
  âœ“ output/vocab/embedding_matrix.npy


ğŸ‹ï¸ TRAINING (FASE 1-4)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Start fresh training:
$ python train.py

Resume from checkpoint:
$ python train.py output/saved_models/checkpoint_epoch_10.pth

Monitor training:
  - Check terminal output (loss, BLEU score)
  - Checkpoints saved to: output/saved_models/
  - Best model: output/saved_models/best_model.pth


ğŸ”® INFERENCE (Generate Captions)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Generate caption for one image:
$ python inference.py --image path/to/image.jpg

With visualization:
$ python inference.py --image path/to/image.jpg --show

Use specific checkpoint:
$ python inference.py \
    --image path/to/image.jpg \
    --checkpoint output/saved_models/checkpoint_epoch_20.pth


ğŸ§ª TESTING & DEBUGGING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Test encoder:
$ python models/encoder.py

Test decoder:
$ python models/decoder.py

Test vocabulary:
$ python utils/vocabulary.py

Test dataset loader:
$ python utils/dataset.py

View pipeline diagram:
$ python PIPELINE_DIAGRAM.py

Check GPU availability:
$ python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"


âš™ï¸  CONFIGURATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Edit config.py to change:
  - CNN model: VGG16 / ResNet50 / ResNet101
  - Batch size, learning rate, epochs
  - LSTM hidden size, dropout
  - Data split, caption length

Common adjustments:
  CNN_MODEL = 'resnet50'      # Change encoder
  BATCH_SIZE = 16             # Reduce if GPU memory error
  NUM_EPOCHS = 30             # More epochs for better results
  LEARNING_RATE = 5e-5        # Lower LR for fine-tuning


ğŸ“Š MONITORING & EVALUATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

During training, monitor:
  - Training loss (should decrease)
  - Validation loss (should decrease)
  - BLEU-4 score (should increase)
  - Sample generated captions

Target BLEU scores:
  BLEU < 0.20  â†’ Poor (needs more training)
  BLEU 0.20-0.35 â†’ Fair (improving)
  BLEU 0.35-0.45 â†’ Good (usable)
  BLEU > 0.45    â†’ Excellent


ğŸ”§ COMMON ISSUES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Issue: "FastText model not found"
Fix: Download cc.id.300.bin to fasttext/ folder

Issue: "CUDA out of memory"
Fix: Reduce BATCH_SIZE in config.py (try 16 or 8)

Issue: "Vocabulary not found"
Fix: Run prepare_data.py first

Issue: Poor caption quality
Fix: Train longer (30-50 epochs), check BLEU > 0.30

Issue: Training too slow
Fix: Use GPU, reduce batch size, or use smaller CNN (VGG16)


ğŸ“ PROJECT STRUCTURE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Kode/
â”œâ”€â”€ config.py              # Hyperparameters âš™ï¸
â”œâ”€â”€ prepare_data.py        # Build vocab (FASE 0) ğŸ“š
â”œâ”€â”€ train.py              # Training (FASE 1-4) ğŸ‹ï¸
â”œâ”€â”€ inference.py          # Generate captions ğŸ”®
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ encoder.py        # CNN (VGG/ResNet)
â”‚   â””â”€â”€ decoder.py        # LSTM
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ vocabulary.py     # Vocab + embeddings
â”‚   â””â”€â”€ dataset.py        # DataLoader
â”œâ”€â”€ Dataset/              # Dataset folder ğŸ“‚
â”œâ”€â”€ fasttext/             # FastText model ğŸŒ‰
â””â”€â”€ output/               # Results ğŸ’¾
    â”œâ”€â”€ saved_models/     # Checkpoints
    â”œâ”€â”€ vocab/           # Vocab files
    â””â”€â”€ logs/            # Logs


ğŸ“š DOCUMENTATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Full guide: README.md
Pipeline diagram: PIPELINE_DIAGRAM.py
Config reference: config.py
Quick start: ./setup.sh


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ¨ TYPICAL WORKFLOW:

1. ./setup.sh                      # One-time setup
2. python prepare_data.py          # Build vocab (once)
3. python train.py                 # Train model (long)
4. python inference.py --image ... # Test on images

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EOF
